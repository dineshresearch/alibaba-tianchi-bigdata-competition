{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pay = pd.read_csv('../preprocess/payTH_parallel.txt', sep=\" \", header = None)\n",
    "trainFile = '../preprocess/trainValidFeatures_ensemble.csv'\n",
    "testFile = '../preprocess/validFeatures_ensemble.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trainLabel = pay[np.arange(447, 475)].values.reshape(1, -1)[0]\n",
    "testLabel = pay[np.arange(475, 489)].values.reshape(1, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trainData = pd.read_csv(trainFile, header = None)\n",
    "testData = pd.read_csv(testFile, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def detectNaN(a):\n",
    "    for i in range(len(a[0])):\n",
    "        e = True\n",
    "        for j in range(len(a) - 1):\n",
    "            if np.isnan(a[j][i]):\n",
    "                e = False\n",
    "                break\n",
    "        if (not e):\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def replace(a):\n",
    "    for i in range(len(a[0])):\n",
    "        e = True\n",
    "        for j in range(len(a)):\n",
    "            if np.isnan(a[j][i]):\n",
    "                a[j][i] = a[j - 1][i]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trainDataArray = np.array(trainData)\n",
    "trainDataArrayProcessed = np.delete(trainDataArray, [1, 2], 1)\n",
    "trainDataProcessed = replace(trainDataArrayProcessed)\n",
    "detectNaN(trainDataProcessed)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(trainDataProcessed)\n",
    "trainDataNormalized = scaler.transform(trainDataProcessed)\n",
    "detectNaN(trainDataNormalized)\n",
    "\n",
    "testDataArray = np.array(testData)\n",
    "testDataArrayProcessed = np.delete(testDataArray, [1, 2], 1)\n",
    "testDataProcessed = replace(testDataArrayProcessed)\n",
    "detectNaN(testDataProcessed)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(testDataProcessed)\n",
    "testDataNormalized = scaler.transform(testDataProcessed)\n",
    "detectNaN(testDataNormalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "alphaList = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10]\n",
    "iterationList = [500, 750, 1000, 1250, 1500, 1750, 2000]\n",
    "minLoss = 10\n",
    "bestAlpha = 0\n",
    "bestIteration = 0\n",
    "timeUsed = []\n",
    "for alpha in alphaList:\n",
    "    for iteration in iterationList:\n",
    "        reg = MLPRegressor(hidden_layer_sizes=(100, 1000, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,100,100,100,100,100,100,100,100,100,100,1000,100,100), early_stopping = True,  alpha = alpha, learning_rate = 'adaptive', max_iter = iteration)\n",
    "        t_start = time.time()\n",
    "        reg.fit(trainDataNormalized, trainLabel)\n",
    "        predictedLabel= reg.predict(testDataNormalized)\n",
    "        t_finish = time.time()\n",
    "        timeUsed.append(t_finish - t_start)\n",
    "        result = sum(abs((abs(predictedLabel) - testLabel) / (abs(predictedLabel) + testLabel)) / (14 * 2000))\n",
    "        if (result < minLoss):\n",
    "            minLoss = result\n",
    "            bestAlpha = alpha\n",
    "            bestIteration = iteration     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
